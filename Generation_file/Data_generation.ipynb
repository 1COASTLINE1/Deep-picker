{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is intended solely for testing purposes and is not to be used for any commercial activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def gaussian(x, A, cen, sigma):\n",
    "    ln2 = np.log(2)\n",
    "    PI = np.pi\n",
    "    amplitude = A  # 振幅乘以浓度\n",
    "    return (amplitude * np.sqrt(4 * ln2) / (sigma * np.sqrt(PI))) * np.exp(-4 * ln2 * (x - cen)**2 / (sigma**2))\n",
    "\n",
    "def generate_data(areas, centers, sigma, noise_level):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    x = np.linspace(0, 100, 100)  # x轴范围和点数\n",
    "\n",
    "    # 生成所有可能的峰组合\n",
    "    combinations = list(itertools.product(areas, repeat=len(centers)))\n",
    "\n",
    "    for combination in combinations:\n",
    "        y_total = np.zeros_like(x)\n",
    "        for area, center in zip(combination, centers):\n",
    "            y_total += gaussian(x, area, center, sigma)\n",
    "        \n",
    "        # 加入噪声\n",
    "        y_total += np.random.normal(0, noise_level, x.shape)\n",
    "    \n",
    "        X_data.append(x.tolist())\n",
    "        y_combination = []\n",
    "        for yi in y_total:\n",
    "            y_combination.append([yi, combination[0], centers[0], sigma])\n",
    "        y_data.append(y_combination)\n",
    "    \n",
    "    return np.array(X_data), np.array(y_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生数据并存入excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def generate_data_set(area, center, sigma, noise_level, file_name=\"gaussian_peaks.xlsx\"):\n",
    "    \n",
    "    # 删除之前的数据\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "\n",
    "    # 生成数据\n",
    "    X_data, y_data = generate_data(area, center, sigma, noise_level)\n",
    "\n",
    "    # 查看前三个样本\n",
    "    \"\"\"\n",
    "    for i in range(3):  \n",
    "        print(f\"Labels for Sample {i+1}:\")\n",
    "        for j, label in enumerate(y_data[i]):\n",
    "            print(f\"  Y: {label[0]}, Area: {label[1]}, Center: {label[2]}, Sigma: {label[3]}\")\n",
    "    \"\"\"\n",
    "\n",
    "    # 导出数据到Excel\n",
    "    max_rows_per_sheet = 1048576  # Excel单个工作表的最大行数\n",
    "    rows_per_sample = 100  # 每个样本的行数\n",
    "    samples_per_sheet = max_rows_per_sheet // rows_per_sample\n",
    "\n",
    "    # 转换元数据为DataFrame\n",
    "    meta_data_list = []\n",
    "    for i in range(len(y_data)):\n",
    "        sample_number = i + 1\n",
    "        for j, label in enumerate(y_data[i]):\n",
    "            meta_data_list.append({\n",
    "                \"Sample\": sample_number,\n",
    "                \"Point\": j + 1,\n",
    "                \"Y\": label[0],\n",
    "                \"Area\": label[1],\n",
    "                \"Center\": label[2],\n",
    "                \"Sigma\": label[3]\n",
    "            })\n",
    "\n",
    "    df_meta = pd.DataFrame(meta_data_list)\n",
    "\n",
    "    # 转换实际数据为DataFrame\n",
    "    data_list = []\n",
    "    for i in range(len(X_data)):\n",
    "        sample_number = i + 1\n",
    "        for x_value in X_data[i]:\n",
    "            data_list.append({\n",
    "                \"Sample\": sample_number,\n",
    "                \"X\": x_value\n",
    "            })\n",
    "\n",
    "    df_data = pd.DataFrame(data_list)\n",
    "\n",
    "    # 将数据分成多个工作表\n",
    "    with pd.ExcelWriter(file_name) as writer:\n",
    "        df_meta.to_excel(writer, sheet_name=\"Metadata\", index=False)\n",
    "        \n",
    "        for start in range(0, len(X_data), samples_per_sheet):\n",
    "            end = min(start + samples_per_sheet, len(X_data))\n",
    "            df_data_subset = df_data[df_data[\"Sample\"].between(start + 1, end)]\n",
    "            df_data_subset.to_excel(writer, sheet_name=f\"Data_{start // samples_per_sheet + 1}\", index=False)\n",
    "\n",
    "    print(f\"Data successfully exported to {file_name}\")\n",
    "\n",
    "    # 自动打开Excel文件（根据需要取消注释）\n",
    "    # os.system(\"start EXCEL.EXE gaussian_peaks.xlsx\")\n",
    "\n",
    "    return X_data, y_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 分别画出后10个样本\\nfor i in range(10):\\n    plt.plot(X_data[i], y_data[i])\\n    plt.title(f\"Generated Data with Peaks {i+1}\")\\n    plt.xlabel(\"X\")\\n    plt.ylabel(\"Y\")\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_combinations(Training_area, Training_center, sigma, noise_level):\n",
    "    # 生成所有可能的峰组合\n",
    "    combinations = list(itertools.product(Training_area, repeat=len(Training_center)))\n",
    "    x = np.linspace(0, 100, 100)  # x轴范围和点数\n",
    "\n",
    "    for combination in combinations:\n",
    "        y_total = np.zeros_like(x)\n",
    "        label = []\n",
    "        for area, center in zip(combination, Training_center):\n",
    "            y_total += gaussian(x, area, center, sigma)\n",
    "            label.append({\n",
    "                \"area\": area, \n",
    "                \"center\": center, \n",
    "                \"sigma\": sigma, \n",
    "                \"noise_level\": noise_level\n",
    "            })\n",
    "    \n",
    "    # 打印所有生成的组合\n",
    "    for combination in combinations:\n",
    "        print(combination)\n",
    "#test_combinations(Training_area, Training_center, sigma, noise_level)\n",
    "\n",
    "#X_data, y_data, labels = generate_data_set(Training_area, Training_center, sigma, noise_level,file_name=\"gaussian_peaks.xlsx\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# 分别画出后10个样本\n",
    "for i in range(10):\n",
    "    plt.plot(X_data[i], y_data[i])\n",
    "    plt.title(f\"Generated Data with Peaks {i+1}\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 筛选出类别1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_peak_picking(x, y_total, user_scales, noise_level, peak_diag=2):\n",
    "    all_p1, all_p2, all_p_type = [], [], []\n",
    "    count_finish = 0\n",
    "\n",
    "    for idx, (row_x, row_y_data, user_scale) in enumerate(zip(x, y_total, user_scales)):\n",
    "        row_y = [item[0] for item in row_y_data]  # Extract y values\n",
    "        min_intensity = noise_level * user_scale\n",
    "        #print(f\"Sample {idx+1}: Minimal peak intensity is set to {min_intensity}\")\n",
    "\n",
    "        count_class1 = 0\n",
    "    \n",
    "        p1, p2, p_type = [], [], []\n",
    "        for i in range(1, len(row_x) - 1):\n",
    "            if row_y[i] > row_y[i - 1] and row_y[i] > row_y[i + 1] and row_y[i] > min_intensity:\n",
    "                ndiag = 0\n",
    "                if i > 1 and row_y[i] > row_y[i - 2]:\n",
    "                    ndiag += 1\n",
    "                if i < len(row_x) - 2 and row_y[i] > row_y[i + 2]:\n",
    "                    ndiag += 1\n",
    "                if i > 1 and row_y[i] > row_y[i - 2]:\n",
    "                    ndiag += 1\n",
    "                if i < len(row_x) - 2 and row_y[i] > row_y[i + 2]:\n",
    "                    ndiag += 1\n",
    "                if ndiag >= peak_diag:\n",
    "                    p1.append(row_x[i])\n",
    "                    p2.append(row_y[i])\n",
    "                    p_type.append(1)\n",
    "                    count_class1 += 1\n",
    "\n",
    "        #print(f\"Sample {idx+1}: Found {count_class1} class1 peaks\")\n",
    "        \n",
    "        if count_class1 >= 5:  # 修改为 >= 5，以确保至少有 5 个峰值\n",
    "            count_finish += 1\n",
    "        all_p1.append(p1)\n",
    "        all_p2.append(p2)\n",
    "        all_p_type.append(p_type)\n",
    "\n",
    "    print(f\"Class1 has been successfully classified\")\n",
    "        \n",
    "    return all_p1, all_p2, all_p_type, count_finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 筛选出类别2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_laplace\n",
    "\n",
    "def get_median_width_x(sigmas):\n",
    "    \"\"\"Calculate the median width of the Gaussian peaks.\"\"\"\n",
    "    return np.median(sigmas)\n",
    "\n",
    "\n",
    "def laplacing_of_gaussian_convolution(data, sigma):\n",
    "    \"\"\"Apply Laplacian of Gaussian convolution to 2D data.\"\"\"\n",
    "    return gaussian_laplace(data, sigma=sigma)\n",
    "\n",
    "def shoulder_peak_picking(x, y_total, user_scales, noise_level, median_width_x, peak_diag=2):\n",
    "    all_p1, all_p2, all_p_type = [], [], []\n",
    "\n",
    "    for idx, (row_x, row_y_data, user_scale) in enumerate(zip(x, y_total, user_scales)):\n",
    "        row_y = [item[0] for item in row_y_data]  # Extract y values\n",
    "        min_intensity = noise_level * user_scale\n",
    "        #print(f\"Sample {idx+1}: Minimal peak for shoulder intensity is set to {min_intensity}\")\n",
    "\n",
    "        xdim = len(row_x)\n",
    "        nshoulder1 = int(median_width_x / 2)\n",
    "\n",
    "        peak_map = np.zeros(xdim, dtype=int)\n",
    "        p1, p2, p_type = [], [], []\n",
    "\n",
    "        shoulder = laplacing_of_gaussian_convolution(row_y, median_width_x / np.sqrt(2))\n",
    "\n",
    "        for i in range(1, xdim - 1):\n",
    "            if (shoulder[i] > shoulder[i - 1] and shoulder[i] > shoulder[i + 1] and \n",
    "                row_y[i] > min_intensity and peak_map[i] == 0):\n",
    "                \n",
    "                ndiag = 0\n",
    "                if i > 1 and shoulder[i] > shoulder[i - 2]:\n",
    "                    ndiag += 1\n",
    "                if i < xdim - 2 and shoulder[i] > shoulder[i + 2]:\n",
    "                    ndiag += 1\n",
    "                if i > 1 and shoulder[i] > shoulder[i - 2]:\n",
    "                    ndiag += 1\n",
    "                if i < xdim - 2 and shoulder[i] > shoulder[i + 2]:\n",
    "                    ndiag += 1\n",
    "\n",
    "                if ndiag >= peak_diag:\n",
    "                    p1.append(row_x[i])\n",
    "                    p2.append(row_y[i])\n",
    "                    p_type.append(2)\n",
    "                    peak_map[i] = 1  # Mark the peak as detected\n",
    "\n",
    "        all_p1.append(p1)\n",
    "        all_p2.append(p2)\n",
    "        all_p_type.append(p_type)\n",
    "\n",
    "    print(f\"Class2 has been successfully classified\")\n",
    "\n",
    "    return all_p1, all_p2, all_p_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def save_peaks_to_excel(x, y_total, class1_results, class2_results):\n",
    "    class1_count = 0\n",
    "    class2_count = 0\n",
    "    count_all = 0\n",
    "\n",
    "    # 创建空的训练数据和目标标签列表\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    p1_class1, p2_class1, p_type_class1, count_all_class1 = class1_results\n",
    "    p1_class2, p2_class2, p_type_class2 = class2_results\n",
    "\n",
    "    for idx, (row_x, row_y_data) in enumerate(zip(x, y_total)):\n",
    "        # 提取附加信息\n",
    "        areas = [item[1] for item in row_y_data]\n",
    "        centers = [item[2] for item in row_y_data]\n",
    "        sigmas = [item[3] for item in row_y_data]\n",
    "\n",
    "        # 初始化所有点为 class 0\n",
    "        classes = np.zeros(len(row_y_data), dtype=int)\n",
    "\n",
    "        # 将已分类的点标记为 class 1\n",
    "        class1_present = False\n",
    "        for px, py, pt in zip(p1_class1[idx], p2_class1[idx], p_type_class1[idx]):\n",
    "            idx_x = np.where(row_x == px)[0]\n",
    "            if len(idx_x) > 0:\n",
    "                classes[idx_x[0]] = pt\n",
    "                class1_present = True\n",
    "        \n",
    "        if class1_present:\n",
    "            class1_count += 1\n",
    "\n",
    "        # 将已分类的点标记为 class 2\n",
    "        class2_present = False\n",
    "        for px, py, pt in zip(p1_class2[idx], p2_class2[idx], p_type_class2[idx]):\n",
    "            idx_x = np.where(row_x == px)[0]\n",
    "            if len(idx_x) > 0:\n",
    "                classes[idx_x[0]] = pt\n",
    "                class2_present = True\n",
    "        \n",
    "        if class2_present:\n",
    "            class2_count += 1\n",
    "\n",
    "        # 将附加信息与分类标签一起添加到 train_y\n",
    "        train_x.append(list(row_x))\n",
    "        train_y.append([[cls, area, center, sigma] for cls, area, center, sigma in zip(classes, areas, centers, sigmas)])\n",
    "\n",
    "        count_all += 1\n",
    "\n",
    "    return class1_count, class2_count, count_all, train_x, train_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Find user_scale and  create training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully exported to gaussian_peaks_train.xlsx\n",
      "Data successfully exported to gaussian_peaks_test.xlsx\n",
      "X_data shape: (7776, 100)\n",
      "y_data shape: (7776, 100, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# 分别画出后10个样本\\nfor i in range(10):\\n    plt.plot(X_data[i], y_data[i])\\n    plt.title(f\"Generated Data with Peaks {i+1}\")\\n    plt.xlabel(\"X\")\\n    plt.ylabel(\"Y\")\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set\n",
    "Training_area = [0,1,5,50,95,100]\n",
    "Training_center = [20,30,40,60,70]\n",
    "sigma =  8   # 固定半高全宽\n",
    "noise_level = 1/300  # 噪声水平\n",
    "\n",
    "\"\"\"\n",
    "Training_area = [0,5,40,60,95,100]\n",
    "Training_center = [20,30,40,60,70]\n",
    "sigma =  8   # 固定半高全宽\n",
    "noise_level = 1/300  # 噪声水平\n",
    "\"\"\"\n",
    "\n",
    "# Test set\n",
    "Test_area =  [0,2,30,60,100] \n",
    "Test_center = [20,30,40,60,70]  \n",
    "sigma = 8    # 固定半高全宽\n",
    "noise_level = 1/300  # 噪声水平\n",
    "\n",
    "\"\"\"\n",
    "Test_area =  [0,30,60,100] \n",
    "Test_center = [20,30,40,60,70]  \n",
    "sigma = 8    # 固定半高全宽\n",
    "noise_level = 1/300  # 噪声水平\n",
    "\"\"\"\n",
    "\n",
    "def test_combinations(Training_area, Training_center, sigma, noise_level):\n",
    "    # 生成所有可能的峰组合\n",
    "    combinations = list(itertools.product(Training_area, repeat=len(Training_center)))\n",
    "    x = np.linspace(0, 100, 100)  # x轴范围和点数\n",
    "\n",
    "    for combination in combinations:\n",
    "        y_total = np.zeros_like(x)\n",
    "        label = []\n",
    "        for area, center in zip(combination, Training_center):\n",
    "            y_total += gaussian(x, area, center, sigma)\n",
    "            label.append({\n",
    "                \"area\": area, \n",
    "                \"center\": center, \n",
    "                \"sigma\": sigma, \n",
    "                \"noise_level\": noise_level\n",
    "            })\n",
    "    \n",
    "    # 打印所有生成的组合\n",
    "    for combination in combinations:\n",
    "        print(combination)\n",
    "#test_combinations(Training_area, Training_center, sigma, noise_level)\n",
    "\n",
    "# Training set\n",
    "X_data, y_data = generate_data_set(Training_area, Training_center, sigma, noise_level,file_name=\"gaussian_peaks_train.xlsx\")\n",
    "train_user_scales = [np.max([item[0] for item in sublist]) for sublist in y_data]\n",
    "\n",
    "\n",
    "# Test set\n",
    "X_test_data, y_test_data= generate_data_set(Test_area, Test_center, sigma, noise_level,file_name=\"gaussian_peaks_test.xlsx\")\n",
    "test_user_scales = [np.max([item[0] for item in sublist]) for sublist in y_test_data]\n",
    "\n",
    "\n",
    "print(f\"X_data shape: {X_data.shape}\")\n",
    "print(f\"y_data shape: {y_data.shape}\")\n",
    "\"\"\"\n",
    "# 分别画出后10个样本\n",
    "for i in range(10):\n",
    "    plt.plot(X_data[i], y_data[i])\n",
    "    plt.title(f\"Generated Data with Peaks {i+1}\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class1 has been successfully classified\n",
      "Class2 has been successfully classified\n",
      "[3.0303030303030303, 5.050505050505051, 7.070707070707071, 10.101010101010102, 13.131313131313131, 15.151515151515152, 19.191919191919194, 21.212121212121215, 25.252525252525253, 29.292929292929294, 32.323232323232325, 34.343434343434346, 37.37373737373738, 39.3939393939394, 42.42424242424243, 44.44444444444445, 47.47474747474748, 50.505050505050505, 53.535353535353536, 56.56565656565657, 61.61616161616162, 64.64646464646465, 67.67676767676768, 69.6969696969697, 76.76767676767678, 80.80808080808082, 85.85858585858587, 90.90909090909092, 93.93939393939395, 97.97979797979798]\n"
     ]
    }
   ],
   "source": [
    "#test shoulder_peak_picking\n",
    "median_width_x = get_median_width_x(sigma)\n",
    "#print(y_data.shape)\n",
    "class1_results = normal_peak_picking(X_data, y_data, train_user_scales, noise_level)\n",
    "class2_results = shoulder_peak_picking(X_data, y_data,train_user_scales, noise_level,median_width_x)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "if os.path.exists(\"Train_Classification.xlsx\"):\n",
    "    os.remove(\"Train_Classification.xlsx\")\n",
    "\"\"\"\n",
    "\n",
    "#with pd.ExcelWriter(\"Train_Classification.xlsx\") as writer:\n",
    "\n",
    "count1,count2,count_all,train_x,train_y = save_peaks_to_excel(X_data, y_data, class1_results, class2_results)\n",
    "\n",
    "\n",
    "\n",
    "#os.system(\"start EXCEL.EXE Classification.xlsx\")\n",
    "print(class1_results[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生训练数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef create_training_set(train_x, train_y, file_name=\"train_data.xlsx\"):\\n\\n    if os.path.exists(file_name):\\n        os.remove(file_name)\\n\\n    with pd.ExcelWriter(file_name) as writer:\\n        for i, (x, y) in enumerate(zip(train_x, train_y)):\\n            # 将 x 和 y 转换为 pandas DataFrame\\n            df = pd.DataFrame({\\n                \\'X\\': x,\\n                \\'Y\\': y\\n            })\\n\\n            # 将 DataFrame 写入一个新的工作表\\n            df.to_excel(writer, sheet_name=f\\'Sample_{i+1}\\', index=False)\\n\\n\\n\\ncreation = create_training_set(train_x, train_y, file_name=\"train_data.xlsx\")\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\"\"\"\n",
    "def create_training_set(train_x, train_y, file_name=\"train_data.xlsx\"):\n",
    "\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "\n",
    "    with pd.ExcelWriter(file_name) as writer:\n",
    "        for i, (x, y) in enumerate(zip(train_x, train_y)):\n",
    "            # 将 x 和 y 转换为 pandas DataFrame\n",
    "            df = pd.DataFrame({\n",
    "                'X': x,\n",
    "                'Y': y\n",
    "            })\n",
    "\n",
    "            # 将 DataFrame 写入一个新的工作表\n",
    "            df.to_excel(writer, sheet_name=f'Sample_{i+1}', index=False)\n",
    "\n",
    "\n",
    "\n",
    "creation = create_training_set(train_x, train_y, file_name=\"train_data.xlsx\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def generate_data_frame(x, y_data):\n",
    "    # 提取 Y 值和附加信息\n",
    "    y_values = [item[0] for item in y_data]\n",
    "    areas = [item[1] for item in y_data]\n",
    "    centers = [item[2] for item in y_data]\n",
    "    sigmas = [item[3] for item in y_data]\n",
    "        \n",
    "    # 创建 DataFrame\n",
    "    return pd.DataFrame({'X': x, 'Y': y_values, 'Area': areas, 'Center': centers, 'Sigma': sigmas})\n",
    "\n",
    "def create_training_set(train_x, train_y, file_name=\"train_data.xlsx\"):\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "\n",
    "    # 生成所有需要写入的数据\n",
    "    data_to_write = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(generate_data_frame, x, y) for x, y in zip(train_x, train_y)]\n",
    "        for i, future in enumerate(futures):\n",
    "            df = future.result()\n",
    "            data_to_write.append((df, f'Sample_{i+1}'))\n",
    "\n",
    "    with pd.ExcelWriter(file_name, engine='xlsxwriter') as writer:\n",
    "        for df, sheet_name in data_to_write:\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# 示例调用\n",
    "create_training_set(train_x, train_y, file_name=\"train_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class1 has been successfully classified\n",
      "Class2 has been successfully classified\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "median_width_x = get_median_width_x(sigma)\n",
    "#print(y_data.shape)\n",
    "test_class1_results = normal_peak_picking(X_test_data, y_test_data, test_user_scales, noise_level)\n",
    "test_class2_results = shoulder_peak_picking(X_test_data, y_data,test_user_scales, noise_level,median_width_x)\n",
    "\n",
    "\"\"\"\n",
    "if os.path.exists(\"Test_Classification.xlsx\"):\n",
    "    os.remove(\"Test_Classification.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(\"Test_Classification.xlsx\") as writer:\"\"\"\n",
    "count1,count2,count_all,test_x,test_y = save_peaks_to_excel(X_test_data, y_test_data, test_class1_results , test_class2_results)\n",
    "    \n",
    "#os.system(\"start EXCEL.EXE Classification.xlsx\")\n",
    "print(count1)\n",
    "print(count2)\n",
    "print(count_all)\n",
    "print(len(test_x))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def generate_data_for_sheet(x, y_data):\n",
    "    y_values = [item[0] for item in y_data]\n",
    "    areas = [item[1] for item in y_data]\n",
    "    centers = [item[2] for item in y_data]\n",
    "    sigmas = [item[3] for item in y_data]\n",
    "    \n",
    "    # 创建 DataFrame\n",
    "    return pd.DataFrame({'X': x, 'Y': y_values, 'Area': areas, 'Center': centers, 'Sigma': sigmas})\n",
    "\n",
    "def create_test_set(train_x, train_y, file_name=\"test_data.xlsx\"):\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "\n",
    "    # 生成所有需要写入的数据\n",
    "    data_to_write = []\n",
    "    for i, (x, y) in enumerate(zip(train_x, train_y)):\n",
    "        data_to_write.append((generate_data_for_sheet(x, y), f'Sample_{i+1}'))\n",
    "\n",
    "    with pd.ExcelWriter(file_name, engine='xlsxwriter') as writer:\n",
    "        # 并行写入\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(write_sheet, writer, data, sheet_name) for data, sheet_name in data_to_write]\n",
    "            for future in futures:\n",
    "                future.result()  # 等待所有线程完成\n",
    "\n",
    "def write_sheet(writer, data, sheet_name):\n",
    "    data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "\n",
    "create_test_set(test_x,test_y , file_name=\"test_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boyangenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
