{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy scipy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 23:54:38.261158: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-26 23:54:38.266054: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-26 23:54:38.306181: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-26 23:54:38.308158: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-26 23:54:38.812640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.1\n",
      "Physical devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "No GPU found. TensorFlow is using CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 23:54:39.369329: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 检查 TensorFlow 版本\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# 列出所有可用的物理设备\n",
    "print(\"Physical devices:\", tf.config.list_physical_devices())\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"Num GPUs Available: \", len(gpus))\n",
    "else:\n",
    "    print(\"No GPU found. TensorFlow is using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import package\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build up basic model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # Hidden Layers\n",
    "    filter_sizes = [40, 20, 10, 20, 10, 30, 18, 18]\n",
    "    kernel_sizes = [11, 1, 11, 1, 1, 11, 1, 3]\n",
    "    x = inputs\n",
    "    for filters, kernel_size in zip(filter_sizes, kernel_sizes):\n",
    "        x = tf.keras.layers.Conv1D(filters, kernel_size, activation='relu', padding='same')(x)\n",
    "\n",
    "    # Max Pooling Layer\n",
    "    x = tf.keras.layers.MaxPooling1D(3)(x)\n",
    "\n",
    "    # Flatten Layer\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    # Classification Layer\n",
    "    classification_output = tf.keras.layers.Dense(input_shape[0], activation='sigmoid')(x)\n",
    "    classification_output = tf.keras.layers.Reshape((input_shape[0],1))(classification_output)\n",
    "    \n",
    "    # Regression Layer\n",
    "    reg_output = tf.keras.layers.Dense(100, name='reg_output')(x)\n",
    "\n",
    "\n",
    "    # Model\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=[classification_output, reg_output])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 100, 1), (None, 100)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = (100,1)  # 示例输入形状\n",
    "num_classes = 2  # 假设有个类别\n",
    "\n",
    "# 创建模型\n",
    "model = create_model(input_shape, num_classes)\n",
    "print(model.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss_function(y_true, y_pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(y_true, -1))\n",
    "    y_true_masked = tf.boolean_mask(y_true, mask)\n",
    "    y_pred_masked = tf.boolean_mask(y_pred, mask)\n",
    "    \n",
    "    return tf.keras.losses.MSE(y_true_masked, y_pred_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    # 使用Adam优化器，学习率为0.002\n",
    "    optimizer = optimizers.Adam(learning_rate=0.002)\n",
    "    \n",
    "    # 为每个输出指定一个损失函数\n",
    "    losses = {\n",
    "        'reshape_1': 'binary_crossentropy',  # 二元分类任务使用交叉熵损失函数\n",
    "        'reg_output': masked_loss_function # 回归任务使用均方误差损失函数\n",
    "    }\n",
    "    \n",
    "    # 为每个输出指定一个评估指标\n",
    "    metrics = {\n",
    "        'reshape_1': 'accuracy',  # 二元分类任务使用准确率作为评估指标\n",
    "        'reg_output': masked_loss_function\n",
    "    }\n",
    "    \n",
    "    # 编译模型\n",
    "    model.compile(optimizer=optimizer, loss=losses, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 示例调用\\nfilename = \"test_data.xlsx\"\\nX_train, y_train_classification, y_train_regression = load_data(filename)\\n\\nprint(f\\'X_train shape: {X_train.shape}\\')\\nprint(f\\'y_train_classification shape: {y_train_classification.shape}\\')\\nprint(f\\'y_train_regression shape: {y_train_regression.shape}\\')\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(filename):\n",
    "    # 读取 Excel 文件中的所有工作表名称\n",
    "    xls = pd.ExcelFile(filename)\n",
    "    sheet_names = xls.sheet_names\n",
    "\n",
    "    # 初始化用于存储所有工作表数据的列表\n",
    "    X_data = []\n",
    "    classification_Y_data = []\n",
    "    regression_Y_data = []\n",
    "\n",
    "    # 遍历每个工作表\n",
    "    for sheet_name in sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "        \n",
    "        # 提取 X 列和 y_classification 列的数据\n",
    "        X = df['X'].to_numpy()\n",
    "        Y = df['y_classification'].to_numpy()\n",
    "        \n",
    "        # 提取 y_regression 列的数据，作为回归任务的目标\n",
    "        reg_target = df['y_regression'].to_numpy()\n",
    "\n",
    "        # 将数据添加到列表中\n",
    "        X_data.append(X)\n",
    "        classification_Y_data.append(Y)\n",
    "        regression_Y_data.append(reg_target)\n",
    "    \n",
    "    # 转换为 NumPy 数组并重塑为 (num_samples, sequence_length, num_features)\n",
    "    X_data = np.array(X_data)\n",
    "    classification_Y_data = np.array(classification_Y_data)\n",
    "    regression_Y_data = np.array(regression_Y_data)\n",
    "\n",
    "    return X_data, classification_Y_data, regression_Y_data\n",
    "\n",
    "\"\"\"\n",
    "# 示例调用\n",
    "filename = \"test_data.xlsx\"\n",
    "X_train, y_train_classification, y_train_regression = load_data(filename)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train_classification shape: {y_train_classification.shape}')\n",
    "print(f'y_train_regression shape: {y_train_regression.shape}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    -1\n",
      "1    -1\n",
      "2    -1\n",
      "3    -1\n",
      "4    -1\n",
      "     ..\n",
      "95   -1\n",
      "96   -1\n",
      "97   -1\n",
      "98   -1\n",
      "99   -1\n",
      "Name: y_regression, Length: 100, dtype: int64\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# 读取 Excel 文件中的一个工作表\n",
    "xls = pd.ExcelFile('test_data.xlsx')\n",
    "df = pd.read_excel(xls, sheet_name='Sample_1')  # 替换 'Sample_1' 为实际工作表名\n",
    "\n",
    "# 打印 y_regression 列的内容和形状\n",
    "print(df['y_regression'])\n",
    "print(df['y_regression'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "def train_classification_model(model, X_train, y_train_classification, y_train_regression, X_val, y_val_classification, y_val_regression):\n",
    "    # 使用所有数据同时进行训练，batch_size设置为训练集大小\n",
    "    batch_size = len(X_train)\n",
    "    \n",
    "    # 训练模型，训练4000个epoch\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train, [y_train_classification, y_train_regression], \n",
    "                        epochs=4000, \n",
    "                        batch_size=batch_size, \n",
    "                        validation_data=(X_val, [y_val_classification, y_val_regression]),\n",
    "                        callbacks=[early_stopping])\n",
    "                       \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_val, y_val_classification, y_val_regression):\n",
    "    # 预测验证集\n",
    "    y_pred_classification, y_pred_regression = model.predict(X_val)\n",
    "    print(f'y_pred_classification shape: {y_pred_classification.shape}')\n",
    "    print(f'y_pred_regression shape: {y_pred_regression.shape}')\n",
    "    \n",
    "    # 将分类预测结果转换为整数标签\n",
    "    y_pred_classes = (y_pred_classification > 0.5).astype(int)\n",
    "    \n",
    "    # 打印调试信息\n",
    "    print(\"Debugging Information:\")\n",
    "    print(f'y_val_classification shape: {y_val_classification.shape}, y_val_classification dtype: {y_val_classification.dtype}')\n",
    "    print(f'y_pred_classes shape: {y_pred_classes.shape}, y_pred_classes dtype: {y_pred_classes.dtype}')\n",
    "    \n",
    "    # 确保 y_val_classification 和 y_pred_classes 的形状一致\n",
    "    y_val_classes = y_val_classification\n",
    "    \n",
    "    # 展开为一维数组\n",
    "    y_val_classes_flat = y_val_classes.flatten()\n",
    "    y_pred_classes_flat = y_pred_classes.flatten()\n",
    "    \n",
    "    # 打印分类报告\n",
    "    print(\"Classification Report:\")\n",
    "    class_report = classification_report(y_val_classes_flat, y_pred_classes_flat, output_dict=True)\n",
    "    print(classification_report(y_val_classes_flat, y_pred_classes_flat))\n",
    "    \n",
    "    # 将分类报告转换为 DataFrame 并写入 CSV 文件\n",
    "    classification_df = pd.DataFrame(class_report).transpose()\n",
    "    classification_df.to_csv('classification_report.csv', index=True)\n",
    "    \n",
    "    # 回归评估\n",
    "    # 打印调试信息以检查形状\n",
    "    print(f'y_val_regression shape: {y_val_regression.shape}')\n",
    "    print(f'y_pred_regression shape: {y_pred_regression.shape}')\n",
    "    \n",
    "    # 确保 y_val_regression 和 y_pred_regression 的形状一致\n",
    "    y_val_regression_flat = y_val_regression.flatten()\n",
    "    y_pred_regression_flat = y_pred_regression.flatten()\n",
    "    \n",
    "    # 再次打印形状以确保一致性\n",
    "    print(f'y_val_regression_flat shape: {y_val_regression_flat.shape}')\n",
    "    print(f'y_pred_regression_flat shape: {y_pred_regression_flat.shape}')\n",
    "    \n",
    "    # 计算回归评估指标\n",
    "    mse = mean_squared_error(y_val_regression_flat, y_pred_regression_flat)\n",
    "    mae = mean_absolute_error(y_val_regression_flat, y_pred_regression_flat)\n",
    "    r2 = r2_score(y_val_regression_flat, y_pred_regression_flat)\n",
    "    \n",
    "    print(\"Regression Evaluation:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R^2 Score: {r2}\")\n",
    "    \n",
    "    # 将回归评估结果写入 CSV 文件\n",
    "    regression_report = {\n",
    "        'Metric': ['Mean Squared Error (MSE)', 'Mean Absolute Error (MAE)', 'R^2 Score'],\n",
    "        'Value': [mse, mae, r2]\n",
    "    }\n",
    "    regression_df = pd.DataFrame(regression_report)\n",
    "    regression_df.to_csv('regression_report.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 1)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 100, 40)              480       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)           (None, 100, 20)              820       ['conv1d_8[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)          (None, 100, 10)              2210      ['conv1d_9[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)          (None, 100, 20)              220       ['conv1d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)          (None, 100, 10)              210       ['conv1d_11[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)          (None, 100, 30)              3330      ['conv1d_12[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)          (None, 100, 18)              558       ['conv1d_13[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)          (None, 100, 18)              990       ['conv1d_14[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPoolin  (None, 33, 18)               0         ['conv1d_15[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 594)                  0         ['max_pooling1d_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 100)                  59500     ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 100, 1)               0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " reg_output (Dense)          (None, 100)                  59500     ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 127818 (499.29 KB)\n",
      "Trainable params: 127818 (499.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object iterparse.<locals>.iterator at 0x78ecce901f90>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/boyang/.conda/envs/boyangenv/lib/python3.8/xml/etree/ElementTree.py\", line 1227, in iterator\n",
      "    yield from pullparser.read_events()\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "# 设置输入形状和类别数量\n",
    "    input_shape = (100,1)  # 示例输入形状\n",
    "    num_classes = 2  # 假设有2个类别\n",
    "\n",
    "    # 创建模型\n",
    "    model = create_model(input_shape, num_classes)\n",
    "    model.summary()\n",
    "\n",
    "    # 编译模型\n",
    "    compile_model(model)\n",
    "\n",
    "# 加载和预处理数据\n",
    "# 从 train_data.xlsx 中加载数据\n",
    "X_train, y_train_classification, y_train_regression = load_data('train_data.xlsx')\n",
    "# 划分训练集和验证集\n",
    "X_train, X_val, y_train_classification, y_val_classification, y_train_regression, y_val_regression = train_test_split(X_train, y_train_classification, y_train_regression, test_size=0.2)\n",
    "\n",
    "# 从 test_data.xlsx 中加载数据（如果有相同的结构）\n",
    "X_test, y_test_classification, y_test_regression = load_data('test_data.xlsx')\n",
    "\n",
    "# 训练模型\n",
    "history = train_classification_model(model, X_train, y_train_classification, y_train_regression, X_val, y_val_classification, y_val_regression)\n",
    "\n",
    "# 评估模型\n",
    "evaluate_model(model, X_test, y_test_classification, y_test_regression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6220, 100)\n",
      "y_train_classification shape: (6220, 100)\n",
      "y_train_regression shape: (6220, 100)\n",
      "X_val shape: (1556, 100)\n",
      "y_val_classification shape: (1556, 100)\n",
      "y_val_regression shape: (1556, 100)\n",
      "X_test shape: (1024, 100)\n",
      "y_test_classification shape: (1024, 100)\n",
      "y_test_regression shape: (1024, 100)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train_classification shape: {y_train_classification.shape}')\n",
    "print(f'y_train_regression shape: {y_train_regression.shape}')\n",
    "print(f'X_val shape: {X_val.shape}')\n",
    "print(f'y_val_classification shape: {y_val_classification.shape}')\n",
    "print(f'y_val_regression shape: {y_val_regression.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_test_classification shape: {y_test_classification.shape}')\n",
    "print(f'y_test_regression shape: {y_test_regression.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 15:19:39.795892: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_68009\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_classification : [[3.24509325e-28]\n",
      " [2.40306987e-30]\n",
      " [1.09750719e-28]\n",
      " [1.55921882e-27]\n",
      " [7.99315940e-31]\n",
      " [1.29024712e-29]\n",
      " [7.62607838e-31]\n",
      " [3.82242747e-29]\n",
      " [1.17351642e-28]\n",
      " [1.03041390e-30]\n",
      " [5.63263981e-27]\n",
      " [8.87126165e-27]\n",
      " [8.25070988e-28]\n",
      " [1.40468651e-28]\n",
      " [9.92297863e-30]\n",
      " [1.59350837e-31]\n",
      " [1.10503177e-27]\n",
      " [1.19083573e-31]\n",
      " [2.77032496e-34]\n",
      " [3.52776170e-27]\n",
      " [7.89793730e-01]\n",
      " [2.08199575e-28]\n",
      " [1.07963856e-29]\n",
      " [2.50243570e-27]\n",
      " [4.93447278e-28]\n",
      " [3.13118769e-27]\n",
      " [7.08966590e-28]\n",
      " [1.70172699e-36]\n",
      " [1.13370564e-31]\n",
      " [3.21666162e-27]\n",
      " [8.47297072e-01]\n",
      " [4.17964323e-29]\n",
      " [3.22838774e-28]\n",
      " [6.28644141e-28]\n",
      " [1.98134495e-32]\n",
      " [2.62250029e-27]\n",
      " [2.55251827e-30]\n",
      " [1.20707447e-27]\n",
      " [1.34368353e-36]\n",
      " [6.57428423e-33]\n",
      " [8.90540540e-01]\n",
      " [4.03799650e-29]\n",
      " [1.50552628e-28]\n",
      " [3.22335615e-27]\n",
      " [9.11881317e-28]\n",
      " [2.76155609e-27]\n",
      " [1.22288337e-27]\n",
      " [8.79808734e-29]\n",
      " [4.68411741e-31]\n",
      " [9.08506838e-27]\n",
      " [4.16152631e-27]\n",
      " [1.68963221e-27]\n",
      " [3.83145312e-27]\n",
      " [9.58666585e-28]\n",
      " [5.65023497e-30]\n",
      " [1.79773388e-26]\n",
      " [1.67363914e-28]\n",
      " [8.57428722e-33]\n",
      " [1.24353083e-26]\n",
      " [6.45375513e-30]\n",
      " [7.92227864e-01]\n",
      " [8.12589325e-28]\n",
      " [9.82119694e-28]\n",
      " [1.06882404e-37]\n",
      " [2.42884057e-28]\n",
      " [1.91948085e-28]\n",
      " [7.75531394e-37]\n",
      " [7.08015013e-36]\n",
      " [7.55078267e-32]\n",
      " [2.32395466e-28]\n",
      " [8.47336948e-01]\n",
      " [1.02263811e-28]\n",
      " [1.23303899e-27]\n",
      " [3.42299478e-35]\n",
      " [1.75935807e-30]\n",
      " [9.33825031e-31]\n",
      " [7.85819760e-31]\n",
      " [8.18168518e-30]\n",
      " [3.69609970e-29]\n",
      " [3.80160395e-29]\n",
      " [2.06693768e-27]\n",
      " [1.69702799e-35]\n",
      " [5.28865139e-27]\n",
      " [2.95918873e-30]\n",
      " [3.47039004e-29]\n",
      " [8.96922331e-28]\n",
      " [5.34089725e-27]\n",
      " [1.54859549e-28]\n",
      " [3.99709427e-28]\n",
      " [1.24199418e-27]\n",
      " [6.76923979e-28]\n",
      " [3.39917795e-30]\n",
      " [2.14432751e-28]\n",
      " [1.49234261e-33]\n",
      " [1.31757075e-33]\n",
      " [6.93457739e-29]\n",
      " [8.50064070e-28]\n",
      " [6.07701146e-28]\n",
      " [1.56787309e-27]\n",
      " [7.08188129e-28]]\n",
      "y_pred_regression : [-3.3306889e+01  1.6673649e+01  7.0968237e+00 -1.2861862e+00\n",
      "  4.4406285e+00 -7.0464668e+00 -8.9593449e+00 -2.8251244e+01\n",
      " -1.1827633e+01  1.2985057e+01 -9.1978321e+00 -2.2736151e+01\n",
      "  2.9539215e+01  1.1241053e+01 -3.1167656e+01  4.5179067e+00\n",
      "  5.3231144e-01 -1.0838147e+01  1.6633549e+00 -9.6969757e+00\n",
      "  5.9877884e+01 -5.6009769e+00  7.8245745e+00  2.2508661e+01\n",
      "  2.2725537e+00 -1.7045006e+01 -1.2817270e+01 -1.1362809e+01\n",
      " -1.9667236e+01  1.0873064e+01  5.9815147e+01  4.9754610e+00\n",
      "  4.7838511e+00  1.2172503e+01  3.0943792e+00 -3.3179478e+01\n",
      " -8.7419109e+00  2.8955703e+00  2.3888601e+01 -1.0161875e+01\n",
      "  6.0247139e+01  7.1176310e+00 -1.7459095e+01  8.1837940e-01\n",
      " -1.1428383e+01 -1.4289207e+01 -7.2917876e+00  6.1519823e+00\n",
      " -1.0274847e+00  1.0325830e+00  8.9515953e+00 -1.1747462e+01\n",
      "  7.5422783e+00  1.2034836e+01 -4.1569247e+00 -1.3526339e+01\n",
      " -5.5724335e+00  4.4150858e+00  1.4625599e+01  1.0364891e+01\n",
      "  6.0236156e+01  1.0231855e+01 -5.9706335e+00 -1.5672596e+01\n",
      "  5.4602771e+00 -2.1580482e+01 -2.6247354e+00  2.2076106e+00\n",
      "  9.9342003e+00 -2.5733385e+01  6.0256390e+01  2.0503063e+00\n",
      " -2.1135145e+01 -3.5648644e+00 -1.2019091e+00  5.1686850e+00\n",
      " -7.1751881e+00 -2.8265633e+01 -1.4663931e+01  1.3146986e+01\n",
      "  9.0365257e+00  7.7439880e+00  1.9300945e+01  2.2409977e+01\n",
      "  2.0672354e+01 -2.4851337e+01 -6.4554138e+00  1.0057931e+01\n",
      " -4.0039182e-02  1.1633565e+01  1.9969036e+01 -4.7127438e-01\n",
      "  1.2983466e+01 -4.7332106e+00 -4.3897338e+00  2.2885038e+01\n",
      "  2.0994802e+01 -2.0510649e+01 -2.0433426e+01  1.9133457e+01]\n",
      "y_val_classification : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_pred_regression : [-3.3306889e+01  1.6673649e+01  7.0968237e+00 -1.2861862e+00\n",
      "  4.4406285e+00 -7.0464668e+00 -8.9593449e+00 -2.8251244e+01\n",
      " -1.1827633e+01  1.2985057e+01 -9.1978321e+00 -2.2736151e+01\n",
      "  2.9539215e+01  1.1241053e+01 -3.1167656e+01  4.5179067e+00\n",
      "  5.3231144e-01 -1.0838147e+01  1.6633549e+00 -9.6969757e+00\n",
      "  5.9877884e+01 -5.6009769e+00  7.8245745e+00  2.2508661e+01\n",
      "  2.2725537e+00 -1.7045006e+01 -1.2817270e+01 -1.1362809e+01\n",
      " -1.9667236e+01  1.0873064e+01  5.9815147e+01  4.9754610e+00\n",
      "  4.7838511e+00  1.2172503e+01  3.0943792e+00 -3.3179478e+01\n",
      " -8.7419109e+00  2.8955703e+00  2.3888601e+01 -1.0161875e+01\n",
      "  6.0247139e+01  7.1176310e+00 -1.7459095e+01  8.1837940e-01\n",
      " -1.1428383e+01 -1.4289207e+01 -7.2917876e+00  6.1519823e+00\n",
      " -1.0274847e+00  1.0325830e+00  8.9515953e+00 -1.1747462e+01\n",
      "  7.5422783e+00  1.2034836e+01 -4.1569247e+00 -1.3526339e+01\n",
      " -5.5724335e+00  4.4150858e+00  1.4625599e+01  1.0364891e+01\n",
      "  6.0236156e+01  1.0231855e+01 -5.9706335e+00 -1.5672596e+01\n",
      "  5.4602771e+00 -2.1580482e+01 -2.6247354e+00  2.2076106e+00\n",
      "  9.9342003e+00 -2.5733385e+01  6.0256390e+01  2.0503063e+00\n",
      " -2.1135145e+01 -3.5648644e+00 -1.2019091e+00  5.1686850e+00\n",
      " -7.1751881e+00 -2.8265633e+01 -1.4663931e+01  1.3146986e+01\n",
      "  9.0365257e+00  7.7439880e+00  1.9300945e+01  2.2409977e+01\n",
      "  2.0672354e+01 -2.4851337e+01 -6.4554138e+00  1.0057931e+01\n",
      " -4.0039182e-02  1.1633565e+01  1.9969036e+01 -4.7127438e-01\n",
      "  1.2983466e+01 -4.7332106e+00 -4.3897338e+00  2.2885038e+01\n",
      "  2.0994802e+01 -2.0510649e+01 -2.0433426e+01  1.9133457e+01]\n",
      "y_val_regression : [ -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1\n",
      "  -1  -1  95  -1  -1  -1  -1  -1  -1  -1  -1  -1 100  -1  -1  -1  -1  -1\n",
      "  -1  -1  -1  -1  60  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1\n",
      "  -1  -1  -1  -1  -1  -1  95  -1  -1  -1  -1  -1  -1  -1  -1  -1   5  -1\n",
      "  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1\n",
      "  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1]\n"
     ]
    }
   ],
   "source": [
    "y_pred_classification, y_pred_regression = model.predict(X_val)\n",
    "print(f'y_pred_classification : {y_pred_classification[1]}')\n",
    "print(f'y_pred_regression : {y_pred_regression[1]}')\n",
    "print(f'y_val_classification : {y_val_classification[1]}')\n",
    "\n",
    "\n",
    "print(f'y_pred_regression : {y_pred_regression[1]}')\n",
    "print(f'y_val_regression : {y_val_regression[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_regression : [-3.3306889e+01  1.6673649e+01  7.0968237e+00 -1.2861862e+00\n",
      "  4.4406285e+00 -7.0464668e+00 -8.9593449e+00 -2.8251244e+01\n",
      " -1.1827633e+01  1.2985057e+01 -9.1978321e+00 -2.2736151e+01\n",
      "  2.9539215e+01  1.1241053e+01 -3.1167656e+01  4.5179067e+00\n",
      "  5.3231144e-01 -1.0838147e+01  1.6633549e+00 -9.6969757e+00\n",
      "  5.9877884e+01 -5.6009769e+00  7.8245745e+00  2.2508661e+01\n",
      "  2.2725537e+00 -1.7045006e+01 -1.2817270e+01 -1.1362809e+01\n",
      " -1.9667236e+01  1.0873064e+01  5.9815147e+01  4.9754610e+00\n",
      "  4.7838511e+00  1.2172503e+01  3.0943792e+00 -3.3179478e+01\n",
      " -8.7419109e+00  2.8955703e+00  2.3888601e+01 -1.0161875e+01\n",
      "  6.0247139e+01  7.1176310e+00 -1.7459095e+01  8.1837940e-01\n",
      " -1.1428383e+01 -1.4289207e+01 -7.2917876e+00  6.1519823e+00\n",
      " -1.0274847e+00  1.0325830e+00  8.9515953e+00 -1.1747462e+01\n",
      "  7.5422783e+00  1.2034836e+01 -4.1569247e+00 -1.3526339e+01\n",
      " -5.5724335e+00  4.4150858e+00  1.4625599e+01  1.0364891e+01\n",
      "  6.0236156e+01  1.0231855e+01 -5.9706335e+00 -1.5672596e+01\n",
      "  5.4602771e+00 -2.1580482e+01 -2.6247354e+00  2.2076106e+00\n",
      "  9.9342003e+00 -2.5733385e+01  6.0256390e+01  2.0503063e+00\n",
      " -2.1135145e+01 -3.5648644e+00 -1.2019091e+00  5.1686850e+00\n",
      " -7.1751881e+00 -2.8265633e+01 -1.4663931e+01  1.3146986e+01\n",
      "  9.0365257e+00  7.7439880e+00  1.9300945e+01  2.2409977e+01\n",
      "  2.0672354e+01 -2.4851337e+01 -6.4554138e+00  1.0057931e+01\n",
      " -4.0039182e-02  1.1633565e+01  1.9969036e+01 -4.7127438e-01\n",
      "  1.2983466e+01 -4.7332106e+00 -4.3897338e+00  2.2885038e+01\n",
      "  2.0994802e+01 -2.0510649e+01 -2.0433426e+01  1.9133457e+01]\n",
      "y_val_regression : [ -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1\n",
      "  -1  -1  95  -1  -1  -1  -1  -1  -1  -1  -1  -1 100  -1  -1  -1  -1  -1\n",
      "  -1  -1  -1  -1  60  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1\n",
      "  -1  -1  -1  -1  -1  -1  95  -1  -1  -1  -1  -1  -1  -1  -1  -1   5  -1\n",
      "  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1\n",
      "  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1]\n"
     ]
    }
   ],
   "source": [
    "print(f'y_pred_regression : {y_pred_regression[1]}')\n",
    "print(f'y_val_regression : {y_val_regression[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boyangenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
