{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is intended solely for testing purposes and is not to be used for any commercial activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef generate_data(areas, centers, sigma, noise_level):\\n    X_data = []\\n    y_data = []\\n    labels = []\\n    x = np.linspace(0, 100, 100)  # x轴范围和点数\\n\\n    # 指定10组较为合理的组合\\n    combinations = [\\n        [(30, 20), (100, 30), (60, 40), (30, 60), (100, 70)]  # 混合组合\\n    ]\\n    \\n    for sigma_test in sigma:\\n        for combination in combinations:\\n            y_total = np.zeros_like(x)\\n            label = []\\n            for area_center in combination:\\n                    y_total += gaussian(x, area_center[0], area_center[1], sigma_test)\\n                    label.append({\\n                        \"area\": area_center[0], \\n                        \"center\": area_center[1], \\n                        \"sigma\": sigma_test, \\n                        \"noise_level\": noise_level\\n                    })\\n\\n        # 加入噪声\\n        y_total += np.random.normal(0, noise_level, x.shape)\\n    \\n        # 添加到数据容器中\\n        X_data.append(x)\\n        y_data.append(y_total)\\n        labels.append(label)\\n    \\n    return np.array(X_data), np.array(y_data), labels\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# 高斯函数定义，添加浓度参数\n",
    "def gaussian(x, A, cen, sigma):\n",
    "    ln2 = np.log(2)\n",
    "    PI = np.pi\n",
    "    amplitude = A  # 振幅乘以浓度\n",
    "    return (amplitude * np.sqrt(4 * ln2) / (sigma * np.sqrt(PI))) * np.exp(-4 * ln2 * (x - cen)**2 / (sigma**2))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def generate_data(num_samples, num_peaks, area, center, sigma, noise_level):\n",
    "    # 生成数据容器\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    labels = []\n",
    "    x = np.linspace(0, 100, 100) \n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # x轴范围和点数\n",
    "\n",
    "        # 随机选择多个浓度\n",
    "        #concentrations = np.random.choice(concentration_list, num_peaks)\n",
    "\n",
    "        # 叠加多个高斯峰\n",
    "        y_total = np.zeros_like(x)\n",
    "        label = []\n",
    "        for area in area:\n",
    "            for center in center:\n",
    "                y_total += gaussian(x, area, center, sigma)\n",
    "                label.append({\n",
    "                    \"area\": area, \n",
    "                    \"center\": center, \n",
    "                    \"sigma\": sigma, \n",
    "                    \"noise_level\": noise_level\n",
    "                })\n",
    "        \n",
    "        # 加入噪声\n",
    "        y_total += np.random.normal(0,  noise_level, x.shape)\n",
    "    \n",
    "        # 添加到数据容器中\n",
    "        X_data.append(x)\n",
    "        y_data.append(y_total)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(X_data), np.array(y_data), labels\n",
    "\"\"\"\n",
    "\n",
    "def generate_data(areas, centers, sigma, noise_level):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    labels = []\n",
    "    x = np.linspace(0, 100, 100)  # x轴范围和点数\n",
    "\n",
    "    # 生成所有可能的峰组合\n",
    "\n",
    "    combinations = list(itertools.product(areas, repeat=len(centers)))\n",
    "\n",
    "    for combination in combinations:\n",
    "        y_total = np.zeros_like(x)\n",
    "        label = []\n",
    "        for area, center in zip(combination, centers):\n",
    "            y_total += gaussian(x, area, center, sigma)\n",
    "            label.append({\n",
    "                \"area\": area, \n",
    "                \"center\": center, \n",
    "                \"sigma\": sigma, \n",
    "                \"noise_level\": noise_level\n",
    "            })\n",
    "        \n",
    "        # 加入噪声\n",
    "        y_total += np.random.normal(0, noise_level, x.shape)\n",
    "    \n",
    "        # 添加到数据容器中\n",
    "        X_data.append(x)\n",
    "        y_data.append(y_total)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(X_data), np.array(y_data), labels\n",
    "\n",
    "\"\"\"\n",
    "def generate_data(areas, centers, sigma, noise_level):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    labels = []\n",
    "    x = np.linspace(0, 100, 100)  # x轴范围和点数\n",
    "\n",
    "    # 指定10组较为合理的组合\n",
    "    combinations = [\n",
    "        [(30, 20), (100, 30), (60, 40), (30, 60), (100, 70)]  # 混合组合\n",
    "    ]\n",
    "    \n",
    "    for sigma_test in sigma:\n",
    "        for combination in combinations:\n",
    "            y_total = np.zeros_like(x)\n",
    "            label = []\n",
    "            for area_center in combination:\n",
    "                    y_total += gaussian(x, area_center[0], area_center[1], sigma_test)\n",
    "                    label.append({\n",
    "                        \"area\": area_center[0], \n",
    "                        \"center\": area_center[1], \n",
    "                        \"sigma\": sigma_test, \n",
    "                        \"noise_level\": noise_level\n",
    "                    })\n",
    "\n",
    "        # 加入噪声\n",
    "        y_total += np.random.normal(0, noise_level, x.shape)\n",
    "    \n",
    "        # 添加到数据容器中\n",
    "        X_data.append(x)\n",
    "        y_data.append(y_total)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(X_data), np.array(y_data), labels\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Test\\n\\n# 参数设置\\nTraining_area = [0,30,60,100]\\nTraining_center = [20, 30, 40, 60, 70]\\nsigma = 8\\nnoise_level = 1 / 300\\n\\nX_data, y_data, labels = generate_data(Training_area, Training_center, sigma, noise_level)\\nprint(X_data.shape)\\n\\n\\n# 分别绘制每组数据\\nfor i in range(len(X_data)):  # 绘制所有组合的数据\\n    plt.figure()\\n    plt.plot(X_data[i], y_data[i])\\n    plt.title(f\"Combination {i+1}\")\\n    for lbl in labels[i]:\\n        print(f\"Area={lbl[\\'area\\']}, Center={lbl[\\'center\\']}, Sigma={lbl[\\'sigma\\']}, Noise Level={lbl[\\'noise_level\\']}\")\\n    plt.xlabel(\"X\")\\n    plt.ylabel(\"Y\")\\n    plt.grid(True)\\n    plt.show()\\n\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Test\n",
    "\n",
    "# 参数设置\n",
    "Training_area = [0,30,60,100]\n",
    "Training_center = [20, 30, 40, 60, 70]\n",
    "sigma = 8\n",
    "noise_level = 1 / 300\n",
    "\n",
    "X_data, y_data, labels = generate_data(Training_area, Training_center, sigma, noise_level)\n",
    "print(X_data.shape)\n",
    "\n",
    "\n",
    "# 分别绘制每组数据\n",
    "for i in range(len(X_data)):  # 绘制所有组合的数据\n",
    "    plt.figure()\n",
    "    plt.plot(X_data[i], y_data[i])\n",
    "    plt.title(f\"Combination {i+1}\")\n",
    "    for lbl in labels[i]:\n",
    "        print(f\"Area={lbl['area']}, Center={lbl['center']}, Sigma={lbl['sigma']}, Noise Level={lbl['noise_level']}\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生数据并存入excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def generate_data_set(area, center, sigma, noise_level,file_name=\"gaussian_peaks.xlsx\"):\n",
    "    \n",
    "    # 删除之前的数据\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "\n",
    "    # 生成数据\n",
    "    X_data, y_data, labels = generate_data(area, center, sigma, noise_level)\n",
    "\n",
    "    # 查看前三个样本\n",
    "    for i in range(3):  \n",
    "        print(f\"Labels for Sample {i+1}:\")\n",
    "        for j, label in enumerate(labels[i]):\n",
    "            print(f\"  Peak {j+1}: {label}\")\n",
    "\n",
    "    # 导出数据到Excel\n",
    "    max_rows_per_sheet = 1048576  # Excel单个工作表的最大行数\n",
    "    rows_per_sample = 100  # 每个样本的行数\n",
    "    samples_per_sheet = max_rows_per_sheet // rows_per_sample\n",
    "\n",
    "    # 转换元数据为DataFrame\n",
    "    meta_data_list = []\n",
    "    for i in range(len(labels)):\n",
    "        sample_number = i + 1\n",
    "        for j, label in enumerate(labels[i]):\n",
    "            meta_data_list.append({\n",
    "                \"Sample\": sample_number,\n",
    "                \"Peak\": j + 1,\n",
    "                \"Area\": label[\"area\"],\n",
    "                \"Center\": label[\"center\"],\n",
    "                \"Sigma\": label[\"sigma\"],\n",
    "                \"Noise Level\": label[\"noise_level\"]\n",
    "            })\n",
    "\n",
    "    df_meta = pd.DataFrame(meta_data_list)\n",
    "\n",
    "    # 转换实际数据为DataFrame\n",
    "    data_list = []\n",
    "    for i in range(len(X_data)):\n",
    "        sample_number = i + 1\n",
    "        for x_value, y_value in zip(X_data[i], y_data[i]):\n",
    "            data_list.append({\n",
    "                \"Sample\": sample_number,\n",
    "                \"X\": x_value,\n",
    "                \"Y\": y_value\n",
    "            })\n",
    "\n",
    "    df_data = pd.DataFrame(data_list)\n",
    "\n",
    "    # 将数据分成多个工作表\n",
    "    with pd.ExcelWriter(file_name) as writer:\n",
    "        df_meta.to_excel(writer, sheet_name=\"Metadata\", index=False)\n",
    "        \n",
    "        for start in range(0, len(X_data), samples_per_sheet):\n",
    "            end = min(start + samples_per_sheet, len(X_data))\n",
    "            df_data_subset = df_data[df_data[\"Sample\"].between(start + 1, end)]\n",
    "            df_data_subset.to_excel(writer, sheet_name=f\"Data_{start // samples_per_sheet + 1}\", index=False)\n",
    "\n",
    "    print(f\"Data successfully exported to {file_name}.xlsx\")\n",
    "\n",
    "    # 自动打开Excel文件\n",
    "    #os.system(\"start EXCEL.EXE gaussian_peaks.xlsx\")\n",
    "\n",
    "    return X_data, y_data, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 分别画出后10个样本\\nfor i in range(10):\\n    plt.plot(X_data[i], y_data[i])\\n    plt.title(f\"Generated Data with Peaks {i+1}\")\\n    plt.xlabel(\"X\")\\n    plt.ylabel(\"Y\")\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set\n",
    "Training_area = [0,30,60,100] \n",
    "Training_center = [20,30,40,60,70]\n",
    "sigma =  8   # 固定半高全宽\n",
    "noise_level = 1/300  # 噪声水平\n",
    "\n",
    "# Test set\n",
    "Test_area = [0,10,90,100] #\n",
    "Test_center = [20,30,40,60,70]  \n",
    "sigma = 8    # 固定半高全宽\n",
    "noise_level = 1/300  # 噪声水平\n",
    "\n",
    "def test_combinations(Training_area, Training_center, sigma, noise_level):\n",
    "    # 生成所有可能的峰组合\n",
    "    combinations = list(itertools.product(Training_area, repeat=len(Training_center)))\n",
    "    x = np.linspace(0, 100, 100)  # x轴范围和点数\n",
    "\n",
    "    for combination in combinations:\n",
    "        y_total = np.zeros_like(x)\n",
    "        label = []\n",
    "        for area, center in zip(combination, Training_center):\n",
    "            y_total += gaussian(x, area, center, sigma)\n",
    "            label.append({\n",
    "                \"area\": area, \n",
    "                \"center\": center, \n",
    "                \"sigma\": sigma, \n",
    "                \"noise_level\": noise_level\n",
    "            })\n",
    "    \n",
    "    # 打印所有生成的组合\n",
    "    for combination in combinations:\n",
    "        print(combination)\n",
    "#test_combinations(Training_area, Training_center, sigma, noise_level)\n",
    "\n",
    "#X_data, y_data, labels = generate_data_set(Training_area, Training_center, sigma, noise_level,file_name=\"gaussian_peaks.xlsx\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# 分别画出后10个样本\n",
    "for i in range(10):\n",
    "    plt.plot(X_data[i], y_data[i])\n",
    "    plt.title(f\"Generated Data with Peaks {i+1}\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 筛选出类别1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_peak_picking(x, y_total, user_scale, noise_level,peak_diag=2):\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "    \"\"\"\n",
    "\n",
    "    min_intensity = noise_level * user_scale\n",
    "    print(f\"Minimal peak intensity is set to {min_intensity}\")\n",
    "\n",
    "    all_p1, all_p2, all_p_type = [], [], []\n",
    "    count_finish = 0\n",
    "\n",
    "    for row_x, row_y in zip(x, y_total):\n",
    "        count_class1 = 0\n",
    "    \n",
    "        p1, p2, p_type = [], [], []\n",
    "        for i in range(1, len(row_x) - 1):\n",
    "            if row_y[i] > row_y[i - 1] and row_y[i] > row_y[i + 1] and row_y[i] > min_intensity:\n",
    "                ndiag = 0\n",
    "                if i > 1 and row_y[i] > row_y[i - 2]:\n",
    "                    ndiag += 1\n",
    "                if i < len(row_x) - 2 and row_y[i] > row_y[i + 2]:\n",
    "                    ndiag += 1\n",
    "                if i > 1 and row_y[i] > row_y[i - 2]:\n",
    "                    ndiag += 1\n",
    "                if i < len(row_x) - 2 and row_y[i] > row_y[i + 2]:\n",
    "                    ndiag += 1\n",
    "                if ndiag >= peak_diag:\n",
    "                    p1.append(row_x[i])\n",
    "                    p2.append(row_y[i])\n",
    "                    p_type.append(1)\n",
    "                    count_class1 += 1\n",
    "        if count_class1 == 5:\n",
    "            count_finish += 1\n",
    "        all_p1.append(p1)\n",
    "        all_p2.append(p2)\n",
    "        all_p_type.append(p_type)\n",
    "\n",
    "    #print(f\"Picked peaks for {len(y_total)} rows\")\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter(file_name) as writer:\n",
    "        for idx, (p1_row, p2_row, p_type_row) in enumerate(zip(all_p1, all_p2, all_p_type)):\n",
    "            if p1_row and p2_row and p_type_row:  # Ensure there are peaks to write and lists are not empty\n",
    "                df = pd.DataFrame({\n",
    "                    'X': p1_row,\n",
    "                    'Y': p2_row,\n",
    "                    'Type': p_type_row\n",
    "                })\n",
    "                df.to_excel(writer, sheet_name=f'Sheet{idx+1}', index=False)\n",
    "            else:\n",
    "                print(f\"No peaks found in row {idx+1}\")\n",
    "\n",
    "\n",
    "    print(f\"Data successfully exported to {file_name}\")\n",
    "    \"\"\"\n",
    "        \n",
    "    #os.system(f\"start EXCEL.EXE {file_name}\")  \n",
    "\n",
    "    print(f\"Class1 has been successfully classified\")\n",
    "        \n",
    "    return all_p1, all_p2, all_p_type, count_finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## test normal_peak_picking\\nX_data, y_data, labels = generate_data_set(Training_area, Training_center, sigma, noise_level,file_name=\"gaussian_peaks.xlsx\")\\np1, p2, p_type,count_finish = normal_peak_picking(X_data, y_data, user_scale, noise_level)\\nprint(count_finish)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## test normal_peak_picking\n",
    "X_data, y_data, labels = generate_data_set(Training_area, Training_center, sigma, noise_level,file_name=\"gaussian_peaks.xlsx\")\n",
    "p1, p2, p_type,count_finish = normal_peak_picking(X_data, y_data, user_scale, noise_level)\n",
    "print(count_finish)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 筛选出类别2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_laplace\n",
    "\n",
    "def get_median_width_x(sigmas):\n",
    "    \"\"\"Calculate the median width of the Gaussian peaks.\"\"\"\n",
    "    return np.median(sigmas)\n",
    "\n",
    "\n",
    "def laplacing_of_gaussian_convolution(data, sigma):\n",
    "    \"\"\"Apply Laplacian of Gaussian convolution to 2D data.\"\"\"\n",
    "    return gaussian_laplace(data, sigma=sigma)\n",
    "\n",
    "def shoulder_peak_picking(x, y_total, user_scale, noise_level, median_width_x, peak_diag=2):\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "    \"\"\"\n",
    "\n",
    "    min_intensity = noise_level * user_scale\n",
    "    print(f\"Minimal peak for shoulder intensity is set to {min_intensity}\")\n",
    "\n",
    "    all_p1, all_p2, all_p_type = [], [], []\n",
    "\n",
    "    for row_x, row_y in zip(x, y_total):\n",
    "        xdim = len(row_x)\n",
    "        nshoulder1 = int(median_width_x / 2)\n",
    "        #print(f\"In shoulder peaks picking, nshoulder is {nshoulder1}\")\n",
    "\n",
    "        peak_map = np.zeros(xdim, dtype=int)\n",
    "        p1, p2, p_type = [], [], []\n",
    "\n",
    "        shoulder = laplacing_of_gaussian_convolution(row_y, median_width_x / np.sqrt(2))\n",
    "\n",
    "        for i in range(1, xdim - 1):\n",
    "            if (shoulder[i] > shoulder[i - 1] and shoulder[i] > shoulder[i + 1] and \n",
    "                row_y[i] > min_intensity and peak_map[i] == 0):\n",
    "                \n",
    "                ndiag = 0\n",
    "                if i > 1 and shoulder[i] > shoulder[i - 2]:\n",
    "                    ndiag += 1\n",
    "                if i < xdim - 2 and shoulder[i] > shoulder[i + 2]:\n",
    "                    ndiag += 1\n",
    "                if i > 1 and shoulder[i] > shoulder[i - 2]:\n",
    "                    ndiag += 1\n",
    "                if i < xdim - 2 and shoulder[i] > shoulder[i + 2]:\n",
    "                    ndiag += 1\n",
    "\n",
    "                if ndiag >= peak_diag:\n",
    "                    p1.append(row_x[i])\n",
    "                    p2.append(row_y[i])\n",
    "                    p_type.append(2)\n",
    "\n",
    "        all_p1.append(p1)\n",
    "        all_p2.append(p2)\n",
    "        all_p_type.append(p_type)\n",
    "\n",
    "    #print(f\"Picked shoulder peaks for {len(y_total)} rows\")\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter(file_name) as writer:\n",
    "        for idx, (p1_row, p2_row, p_type_row) in enumerate(zip(all_p1, all_p2, all_p_type)):\n",
    "            if p1_row and p2_row and p_type_row:  # Ensure there are peaks to write and lists are not empty\n",
    "                df = pd.DataFrame({\n",
    "                    'X': p1_row,\n",
    "                    'Y': p2_row,\n",
    "                    'Type': p_type_row\n",
    "                })\n",
    "                df.to_excel(writer, sheet_name=f'Sheet{idx+1}', index=False)\n",
    "            else:\n",
    "                print(f\"No peaks found in row {idx+1}\")\n",
    "\n",
    "   \n",
    "    \"\"\"\n",
    "\n",
    "    #os.system(f\"start EXCEL.EXE {file_name}\")\n",
    "    print(f\"Class2 has been successfully classified\")\n",
    "\n",
    "    return all_p1, all_p2, all_p_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_peaks_to_excel(writer, sheet_name, x, y_total, class1_results, class2_results):\n",
    "    class1_count = 0\n",
    "    class2_count = 0\n",
    "    count_all = 0\n",
    "\n",
    "    # 创建空的训练数据和目标标签列表\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for idx, (row_x, row_y) in enumerate(zip(x, y_total)):\n",
    "        \n",
    "        p1_class1, p2_class1, p_type_class1,count_all_class1= class1_results\n",
    "        p1_class2, p2_class2, p_type_class2 = class2_results\n",
    "        \n",
    "        # 初始化所有点为 class 0\n",
    "        classes = np.zeros_like(row_y, dtype=int)\n",
    "\n",
    "        # 将已分类的点标记为 class 1\n",
    "        class1_present = False\n",
    "        for px, py, pt in zip(p1_class1[idx], p2_class1[idx], p_type_class1[idx]):\n",
    "            idx_x = np.where(row_x == px)[0]\n",
    "            if len(idx_x) > 0:\n",
    "                classes[idx_x[0]] = pt\n",
    "                class1_present = True\n",
    "        \n",
    "        if class1_present:\n",
    "            class1_count += 1\n",
    "\n",
    "        train_x.append(list(row_x))\n",
    "        train_y.append(list(classes))\n",
    "\n",
    "        # 将已分类的点标记为 class 2\n",
    "        class2_present = False\n",
    "        for px, py, pt in zip(p1_class2[idx], p2_class2[idx], p_type_class2[idx]):\n",
    "            idx_x = np.where(row_x == px)[0]\n",
    "            if len(idx_x) > 0:\n",
    "                classes[idx_x[0]] = pt\n",
    "                class2_present = True\n",
    "        \n",
    "        if class2_present:\n",
    "            class2_count+= 1\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'X': row_x,\n",
    "            'Y': row_y,\n",
    "            'Class': classes\n",
    "        })\n",
    "        df.to_excel(writer, sheet_name=f'{sheet_name}_{idx+1}', index=False)\n",
    "        count_all += 1\n",
    "\n",
    "    return class1_count,class2_count,count_all,train_x, train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Find user_scale and  create training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels for Sample 1:\n",
      "  Peak 1: {'area': 0, 'center': 20, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 2: {'area': 0, 'center': 30, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 3: {'area': 0, 'center': 40, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 4: {'area': 0, 'center': 60, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 5: {'area': 0, 'center': 70, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "Labels for Sample 2:\n",
      "  Peak 1: {'area': 0, 'center': 20, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 2: {'area': 0, 'center': 30, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 3: {'area': 0, 'center': 40, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 4: {'area': 0, 'center': 60, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 5: {'area': 30, 'center': 70, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "Labels for Sample 3:\n",
      "  Peak 1: {'area': 0, 'center': 20, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 2: {'area': 0, 'center': 30, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 3: {'area': 0, 'center': 40, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 4: {'area': 0, 'center': 60, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 5: {'area': 60, 'center': 70, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "Data successfully exported to gaussian_peaks_train.xlsx.xlsx\n",
      "Labels for Sample 1:\n",
      "  Peak 1: {'area': 0, 'center': 20, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 2: {'area': 0, 'center': 30, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 3: {'area': 0, 'center': 40, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 4: {'area': 0, 'center': 60, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 5: {'area': 0, 'center': 70, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "Labels for Sample 2:\n",
      "  Peak 1: {'area': 0, 'center': 20, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 2: {'area': 0, 'center': 30, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 3: {'area': 0, 'center': 40, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 4: {'area': 0, 'center': 60, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 5: {'area': 10, 'center': 70, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "Labels for Sample 3:\n",
      "  Peak 1: {'area': 0, 'center': 20, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 2: {'area': 0, 'center': 30, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 3: {'area': 0, 'center': 40, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 4: {'area': 0, 'center': 60, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 5: {'area': 90, 'center': 70, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "Data successfully exported to gaussian_peaks_test.xlsx.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# 分别画出后10个样本\\nfor i in range(10):\\n    plt.plot(X_data[i], y_data[i])\\n    plt.title(f\"Generated Data with Peaks {i+1}\")\\n    plt.xlabel(\"X\")\\n    plt.ylabel(\"Y\")\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set\n",
    "Training_area = [0,30,60,100] \n",
    "Training_center = [20,30,40,60,70]\n",
    "sigma =  8   # 固定半高全宽\n",
    "noise_level = 1/300  # 噪声水平\n",
    "\n",
    "# Test set\n",
    "Test_area = [0,10,90,100] #\n",
    "Test_center = [20,30,40,60,70]  \n",
    "sigma = 8    # 固定半高全宽\n",
    "noise_level = 1/300  # 噪声水平\n",
    "\n",
    "def test_combinations(Training_area, Training_center, sigma, noise_level):\n",
    "    # 生成所有可能的峰组合\n",
    "    combinations = list(itertools.product(Training_area, repeat=len(Training_center)))\n",
    "    x = np.linspace(0, 100, 100)  # x轴范围和点数\n",
    "\n",
    "    for combination in combinations:\n",
    "        y_total = np.zeros_like(x)\n",
    "        label = []\n",
    "        for area, center in zip(combination, Training_center):\n",
    "            y_total += gaussian(x, area, center, sigma)\n",
    "            label.append({\n",
    "                \"area\": area, \n",
    "                \"center\": center, \n",
    "                \"sigma\": sigma, \n",
    "                \"noise_level\": noise_level\n",
    "            })\n",
    "    \n",
    "    # 打印所有生成的组合\n",
    "    for combination in combinations:\n",
    "        print(combination)\n",
    "#test_combinations(Training_area, Training_center, sigma, noise_level)\n",
    "\n",
    "# Training set\n",
    "X_data, y_data, labels = generate_data_set(Training_area, Training_center, sigma, noise_level,file_name=\"gaussian_peaks_train.xlsx\")\n",
    "train_user_scale = np.max(y_data)  # 用户缩放因子\n",
    "\n",
    "\n",
    "# Test set\n",
    "X_test_data, y_test_data, test_labels = generate_data_set(Test_area, Test_center, sigma, noise_level,file_name=\"gaussian_peaks_test.xlsx\")\n",
    "test_user_scale = np.max(y_test_data)  # 用户缩放因子\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# 分别画出后10个样本\n",
    "for i in range(10):\n",
    "    plt.plot(X_data[i], y_data[i])\n",
    "    plt.title(f\"Generated Data with Peaks {i+1}\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal peak intensity is set to 0.040069446877984104\n",
      "Class1 has been successfully classified\n",
      "Minimal peak for shoulder intensity is set to 0.040069446877984104\n",
      "Class2 has been successfully classified\n",
      "1023\n",
      "972\n",
      "1024\n",
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "#test shoulder_peak_picking\n",
    "median_width_x = get_median_width_x(sigma)\n",
    "#print(y_data.shape)\n",
    "class1_results = normal_peak_picking(X_data, y_data, train_user_scale, noise_level)\n",
    "class2_results = shoulder_peak_picking(X_data, y_data,train_user_scale, noise_level,median_width_x)\n",
    "\n",
    "if os.path.exists(\"Train_Classification.xlsx\"):\n",
    "    os.remove(\"Train_Classification.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(\"Train_Classification.xlsx\") as writer:\n",
    "    count1,count2,count_all,train_x,train_y = save_peaks_to_excel(writer, \"Peak\", X_data, y_data, class1_results, class2_results)\n",
    "    \n",
    "#os.system(\"start EXCEL.EXE Classification.xlsx\")\n",
    "print(count1)\n",
    "print(count2)\n",
    "print(count_all)\n",
    "print(len(train_x))\n",
    "print(len(train_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生训练数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_training_set(train_x, train_y, file_name=\"train_data.xlsx\"):\n",
    "\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "\n",
    "    with pd.ExcelWriter(file_name) as writer:\n",
    "        for i, (x, y) in enumerate(zip(train_x, train_y)):\n",
    "            # 将 x 和 y 转换为 pandas DataFrame\n",
    "            df = pd.DataFrame({\n",
    "                'X': x,\n",
    "                'Y': y\n",
    "            })\n",
    "\n",
    "            # 将 DataFrame 写入一个新的工作表\n",
    "            df.to_excel(writer, sheet_name=f'Sample_{i+1}', index=False)\n",
    "\n",
    "\n",
    "\n",
    "creation = create_training_set(train_x, train_y, file_name=\"train_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels for Sample 1:\n",
      "  Peak 1: {'area': 0, 'center': 20, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 2: {'area': 0, 'center': 30, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 3: {'area': 0, 'center': 40, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 4: {'area': 0, 'center': 60, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 5: {'area': 0, 'center': 70, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "Labels for Sample 2:\n",
      "  Peak 1: {'area': 0, 'center': 20, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 2: {'area': 0, 'center': 30, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 3: {'area': 0, 'center': 40, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 4: {'area': 0, 'center': 60, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 5: {'area': 10, 'center': 70, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "Labels for Sample 3:\n",
      "  Peak 1: {'area': 0, 'center': 20, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 2: {'area': 0, 'center': 30, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 3: {'area': 0, 'center': 40, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 4: {'area': 0, 'center': 60, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "  Peak 5: {'area': 90, 'center': 70, 'sigma': 8, 'noise_level': 0.0033333333333333335}\n",
      "Data successfully exported to gaussian_peaks_test.xlsx.xlsx\n",
      "Minimal peak intensity is set to 0.04005936071832771\n",
      "Class1 has been successfully classified\n",
      "Minimal peak for shoulder intensity is set to 0.04005936071832771\n",
      "Class2 has been successfully classified\n",
      "1023\n",
      "972\n",
      "1024\n",
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "#test shoulder_peak_picking\n",
    "X_test_data, y_test_data, test_labels = generate_data_set(Test_area, Test_center, sigma, noise_level,file_name=\"gaussian_peaks_test.xlsx\")\n",
    "\n",
    "median_width_x = get_median_width_x(sigma)\n",
    "#print(y_data.shape)\n",
    "test_class1_results = normal_peak_picking(X_test_data, y_test_data, test_user_scale, noise_level)\n",
    "test_class2_results = shoulder_peak_picking(X_test_data, y_data,test_user_scale, noise_level,median_width_x)\n",
    "\n",
    "if os.path.exists(\"Test_Classification.xlsx\"):\n",
    "    os.remove(\"Test_Classification.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(\"Test_Classification.xlsx\") as writer:\n",
    "    count1,count2,count_all,test_x,test_y = save_peaks_to_excel(writer, \"Peak\", X_test_data, y_test_data, test_class1_results , test_class2_results)\n",
    "    \n",
    "#os.system(\"start EXCEL.EXE Classification.xlsx\")\n",
    "print(count1)\n",
    "print(count2)\n",
    "print(count_all)\n",
    "print(len(test_x))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_set(test_x, test_y, file_name=\"test_data.xlsx\"):\n",
    "\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "\n",
    "    with pd.ExcelWriter(file_name) as writer:\n",
    "        for i, (x, y) in enumerate(zip(test_x, test_y)):\n",
    "            # 将 x 和 y 转换为 pandas DataFrame\n",
    "            df = pd.DataFrame({\n",
    "                'X': x,\n",
    "                'Y': y\n",
    "            })\n",
    "\n",
    "            # 将 DataFrame 写入一个新的工作表\n",
    "            df.to_excel(writer, sheet_name=f'Sample_{i+1}', index=False)\n",
    "\n",
    "creation = create_test_set(test_x, test_y, file_name=\"test_data.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
